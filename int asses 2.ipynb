{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c0587-c772-448e-9d9e-f289117ccf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data preprocessing,modelling&tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce07661-a877-487b-a6d9-8d82ba49687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| employee_id   | department        | region    | education        | gender   | recruitment_channel   | no_of_trainings   | age   | previous_year_rating   | length_of_service   | KPIs_met >80%   | awards_won?   | avg_training_score   | is_promoted   |\n",
      "|:--------------|:------------------|:----------|:-----------------|:---------|:----------------------|:------------------|:------|:-----------------------|:--------------------|:----------------|:--------------|:---------------------|:--------------|\n",
      "| 65438         | Sales & Marketing | region_7  | Master's & above | f        | sourcing              | 1                 | 35    | 5                      | 8                   | 1               | 0             | 49                   | 0             |\n",
      "| 65141         | Operations        | region_22 | Bachelor's       | m        | other                 | 1                 | 30    | 5                      | 4                   | 0               | 0             | 60                   | 0             |\n",
      "| 7513          | Sales & Marketing | region_19 | Bachelor's       | m        | sourcing              | 1                 | 34    | 3                      | 7                   | 0               | 0             | 50                   | 0             |\n",
      "| 2542          | Sales & Marketing | region_23 | Bachelor's       | m        | other                 | 2                 | 39    | 1                      | 10                  | 0               | 0             | 50                   | 0             |\n",
      "| 48945         | Technology        | region_26 | Bachelor's       | m        | other                 | 1                 | 45    | 3                      | 2                   | 0               | 0             | 73                   | 0             |\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54808 entries, 0 to 54807\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   employee_id           54808 non-null  int64  \n",
      " 1   department            54808 non-null  object \n",
      " 2   region                54808 non-null  object \n",
      " 3   education             52399 non-null  object \n",
      " 4   gender                54808 non-null  object \n",
      " 5   recruitment_channel   54808 non-null  object \n",
      " 6   no_of_trainings       54808 non-null  int64  \n",
      " 7   age                   54808 non-null  int64  \n",
      " 8   previous_year_rating  50684 non-null  float64\n",
      " 9   length_of_service     54808 non-null  int64  \n",
      " 10  KPIs_met >80%         54808 non-null  int64  \n",
      " 11  awards_won?           54808 non-null  int64  \n",
      " 12  avg_training_score    54808 non-null  int64  \n",
      " 13  is_promoted           54808 non-null  int64  \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('train_LZdllcl.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Print the column names and their data types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251bf599-1316-4ca8-a67b-65f85bfaec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column:\n",
      "|                      | 0    |\n",
      "|:---------------------|:-----|\n",
      "| employee_id          | 0    |\n",
      "| department           | 0    |\n",
      "| region               | 0    |\n",
      "| education            | 2409 |\n",
      "| gender               | 0    |\n",
      "| recruitment_channel  | 0    |\n",
      "| no_of_trainings      | 0    |\n",
      "| age                  | 0    |\n",
      "| previous_year_rating | 4124 |\n",
      "| length_of_service    | 0    |\n",
      "| KPIs_met >80%        | 0    |\n",
      "| awards_won?          | 0    |\n",
      "| avg_training_score   | 0    |\n",
      "| is_promoted          | 0    |\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in each column\n",
    "print('Number of missing values in each column:')\n",
    "print(df.isnull().sum().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Print the number of duplicate rows\n",
    "print(f'Number of duplicate rows: {df.duplicated().sum()}')\n",
    "\n",
    "# Drop `employee_id`\n",
    "df = df.drop(columns=['employee_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a88f26-7a86-4470-966d-1c7bfdec9560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column after imputation:\n",
      "|                      | 0   |\n",
      "|:---------------------|:----|\n",
      "| department           | 0   |\n",
      "| region               | 0   |\n",
      "| education            | 0   |\n",
      "| gender               | 0   |\n",
      "| recruitment_channel  | 0   |\n",
      "| no_of_trainings      | 0   |\n",
      "| age                  | 0   |\n",
      "| previous_year_rating | 0   |\n",
      "| length_of_service    | 0   |\n",
      "| KPIs_met >80%        | 0   |\n",
      "| awards_won?          | 0   |\n",
      "| avg_training_score   | 0   |\n",
      "| is_promoted          | 0   |\n",
      "\n",
      "Value counts for categorical columns:\n",
      "\n",
      "Value counts for 'department':\n",
      "| department        | count   |\n",
      "|:------------------|:--------|\n",
      "| Sales & Marketing | 16840   |\n",
      "| Operations        | 11348   |\n",
      "| Technology        | 7138    |\n",
      "| Procurement       | 7138    |\n",
      "| Analytics         | 5352    |\n",
      "| Finance           | 2536    |\n",
      "| HR                | 2418    |\n",
      "| Legal             | 1039    |\n",
      "| R&D               | 999     |\n",
      "\n",
      "Value counts for 'region':\n",
      "| region    | count   |\n",
      "|:----------|:--------|\n",
      "| region_2  | 12343   |\n",
      "| region_22 | 6428    |\n",
      "| region_7  | 4843    |\n",
      "| region_15 | 2808    |\n",
      "| region_13 | 2648    |\n",
      "| region_26 | 2260    |\n",
      "| region_31 | 1935    |\n",
      "| region_4  | 1703    |\n",
      "| region_27 | 1659    |\n",
      "| region_16 | 1465    |\n",
      "| region_28 | 1318    |\n",
      "| region_11 | 1315    |\n",
      "| region_23 | 1175    |\n",
      "| region_29 | 994     |\n",
      "| region_32 | 945     |\n",
      "| region_19 | 874     |\n",
      "| region_20 | 850     |\n",
      "| region_14 | 827     |\n",
      "| region_25 | 819     |\n",
      "| region_17 | 796     |\n",
      "| region_5  | 766     |\n",
      "| region_6  | 690     |\n",
      "| region_30 | 657     |\n",
      "| region_8  | 655     |\n",
      "| region_10 | 648     |\n",
      "| region_1  | 610     |\n",
      "| region_24 | 508     |\n",
      "| region_12 | 500     |\n",
      "| region_9  | 420     |\n",
      "| region_21 | 411     |\n",
      "| region_3  | 346     |\n",
      "| region_34 | 292     |\n",
      "| region_33 | 269     |\n",
      "| region_18 | 31      |\n",
      "\n",
      "Value counts for 'education':\n",
      "| education        | count   |\n",
      "|:-----------------|:--------|\n",
      "| Bachelor's       | 39078   |\n",
      "| Master's & above | 14925   |\n",
      "| Below Secondary  | 805     |\n",
      "\n",
      "Value counts for 'gender':\n",
      "| gender   | count   |\n",
      "|:---------|:--------|\n",
      "| m        | 38496   |\n",
      "| f        | 16312   |\n",
      "\n",
      "Value counts for 'recruitment_channel':\n",
      "| recruitment_channel   | count   |\n",
      "|:----------------------|:--------|\n",
      "| other                 | 30446   |\n",
      "| sourcing              | 23220   |\n",
      "| referred              | 1142    |\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values in `education` with the mode\n",
    "df['education'].fillna(df['education'].mode()[0], inplace=True)\n",
    "\n",
    "# Impute missing values in `previous_year_rating` with the median\n",
    "df['previous_year_rating'].fillna(df['previous_year_rating'].median(), inplace=True)\n",
    "\n",
    "# Print the number of missing values in each column after imputation\n",
    "print('Number of missing values in each column after imputation:')\n",
    "print(df.isnull().sum().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Print value counts for categorical columns\n",
    "print('\\nValue counts for categorical columns:')\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"\\nValue counts for '{column}':\")\n",
    "    print(df[column].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce62a09-9434-4b4d-bd34-033910304654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Logistic Regression Model Performance:\n",
      "Accuracy: 0.9324\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     10028\n",
      "           1       0.82      0.27      0.40       934\n",
      "\n",
      "    accuracy                           0.93     10962\n",
      "   macro avg       0.88      0.63      0.68     10962\n",
      "weighted avg       0.93      0.93      0.92     10962\n",
      "\n",
      "\n",
      "Fine-tuning Logistic Regression with GridSearchCV...\n",
      "Best parameters found: {'classifier__C': 10.0, 'classifier__penalty': 'l1'}\n",
      "Best cross-validation accuracy: 0.9320\n",
      "\n",
      "Fine-tuned Logistic Regression Model Performance (on Test Set):\n",
      "Accuracy: 0.9330\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     10028\n",
      "           1       0.81      0.28      0.41       934\n",
      "\n",
      "    accuracy                           0.93     10962\n",
      "   macro avg       0.87      0.64      0.69     10962\n",
      "weighted avg       0.93      0.93      0.92     10962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('is_promoted', axis=1)\n",
    "y = df['is_promoted']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include='object').columns\n",
    "numerical_features = X.select_dtypes(exclude='object').columns\n",
    "\n",
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a pipeline with preprocessing and a Logistic Regression model\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Initial Logistic Regression Model Performance:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Fine-tuning with GridSearchCV\n",
    "print('\\nFine-tuning Logistic Regression with GridSearchCV...')\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.4f}')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "print('\\nFine-tuned Logistic Regression Model Performance (on Test Set):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_tuned):.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b18c6-a28a-4d42-a9f5-398a776b7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d606bd22-3e9e-45a7-acf8-b927f23a9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| employee_id   | department        | region    | education   | gender   | recruitment_channel   | no_of_trainings   | age   | previous_year_rating   | length_of_service   | KPIs_met >80%   | awards_won?   | avg_training_score   |\n",
      "|:--------------|:------------------|:----------|:------------|:---------|:----------------------|:------------------|:------|:-----------------------|:--------------------|:----------------|:--------------|:---------------------|\n",
      "| 8724          | Technology        | region_26 | Bachelor's  | m        | sourcing              | 1                 | 24    | nan                    | 1                   | 1               | 0             | 77                   |\n",
      "| 74430         | HR                | region_4  | Bachelor's  | f        | other                 | 1                 | 31    | 3                      | 5                   | 0               | 0             | 51                   |\n",
      "| 72255         | Sales & Marketing | region_13 | Bachelor's  | m        | other                 | 1                 | 31    | 1                      | 4                   | 0               | 0             | 47                   |\n",
      "| 38562         | Procurement       | region_2  | Bachelor's  | f        | other                 | 3                 | 31    | 2                      | 9                   | 0               | 0             | 65                   |\n",
      "| 64486         | Finance           | region_29 | Bachelor's  | m        | sourcing              | 1                 | 30    | 4                      | 7                   | 0               | 0             | 61                   |\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23490 entries, 0 to 23489\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   employee_id           23490 non-null  int64  \n",
      " 1   department            23490 non-null  object \n",
      " 2   region                23490 non-null  object \n",
      " 3   education             22456 non-null  object \n",
      " 4   gender                23490 non-null  object \n",
      " 5   recruitment_channel   23490 non-null  object \n",
      " 6   no_of_trainings       23490 non-null  int64  \n",
      " 7   age                   23490 non-null  int64  \n",
      " 8   previous_year_rating  21678 non-null  float64\n",
      " 9   length_of_service     23490 non-null  int64  \n",
      " 10  KPIs_met >80%         23490 non-null  int64  \n",
      " 11  awards_won?           23490 non-null  int64  \n",
      " 12  avg_training_score    23490 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('test_2umaH9m.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Print the column names and their data types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25672f6-5586-44a5-850f-292612e135e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc49db24-0093-4c3e-999b-2cf1cc9ad01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54808 entries, 0 to 54807\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   employee_id           54808 non-null  int64  \n",
      " 1   department            54808 non-null  object \n",
      " 2   region                54808 non-null  object \n",
      " 3   education             52399 non-null  object \n",
      " 4   gender                54808 non-null  object \n",
      " 5   recruitment_channel   54808 non-null  object \n",
      " 6   no_of_trainings       54808 non-null  int64  \n",
      " 7   age                   54808 non-null  int64  \n",
      " 8   previous_year_rating  50684 non-null  float64\n",
      " 9   length_of_service     54808 non-null  int64  \n",
      " 10  KPIs_met >80%         54808 non-null  int64  \n",
      " 11  awards_won?           54808 non-null  int64  \n",
      " 12  avg_training_score    54808 non-null  int64  \n",
      " 13  is_promoted           54808 non-null  int64  \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 5.9+ MB\n",
      "\n",
      "Test DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23490 entries, 0 to 23489\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   employee_id           23490 non-null  int64  \n",
      " 1   department            23490 non-null  object \n",
      " 2   region                23490 non-null  object \n",
      " 3   education             22456 non-null  object \n",
      " 4   gender                23490 non-null  object \n",
      " 5   recruitment_channel   23490 non-null  object \n",
      " 6   no_of_trainings       23490 non-null  int64  \n",
      " 7   age                   23490 non-null  int64  \n",
      " 8   previous_year_rating  21678 non-null  float64\n",
      " 9   length_of_service     23490 non-null  int64  \n",
      " 10  KPIs_met >80%         23490 non-null  int64  \n",
      " 11  awards_won?           23490 non-null  int64  \n",
      " 12  avg_training_score    23490 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 2.3+ MB\n",
      "\n",
      "Starting GridSearchCV for hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "Best parameters found: {'classifier__criterion': 'gini', 'classifier__max_depth': 8, 'classifier__max_features': 'sqrt', 'classifier__n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.9238\n",
      "\n",
      "Evaluating model on the validation set...\n",
      "Validation Accuracy: 0.9247\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     10028\n",
      "           1       0.99      0.12      0.21       934\n",
      "\n",
      "    accuracy                           0.92     10962\n",
      "   macro avg       0.96      0.56      0.59     10962\n",
      "weighted avg       0.93      0.92      0.90     10962\n",
      "\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Process completed. 'submission.csv' has been created with test predictions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- 1. Load the datasets ---\n",
    "# Ensure these CSV files are in the same directory as your script\n",
    "# or provide the full path to them.\n",
    "try:\n",
    "    train_df = pd.read_csv('train_LZdllcl.csv')\n",
    "    test_df = pd.read_csv('test_2umaH9m.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train_LZdllcl.csv' and 'test_2umaH9m.csv' are in the correct directory.\")\n",
    "    print(\"If not, please provide the full path to the files, e.g., pd.read_csv('/path/to/your/train_LZdllcl.csv')\")\n",
    "    exit() # Exit if files are not found\n",
    "\n",
    "# Display initial information about the datasets\n",
    "print(\"Train DataFrame Info:\")\n",
    "train_df.info()\n",
    "print(\"\\nTest DataFrame Info:\")\n",
    "test_df.info()\n",
    "\n",
    "# --- 2. Separate target variable and drop unnecessary columns ---\n",
    "# Separate target variable from the training data\n",
    "X = train_df.drop('is_promoted', axis=1)\n",
    "y = train_df['is_promoted']\n",
    "\n",
    "# Store employee_ids for submission and drop from features\n",
    "test_employee_ids = test_df['employee_id']\n",
    "X = X.drop('employee_id', axis=1)\n",
    "test_df = test_df.drop('employee_id', axis=1)\n",
    "\n",
    "# --- 3. Identify Categorical and Numerical Features ---\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# --- 4. Preprocessing Pipelines ---\n",
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Impute missing numerical values with the mean\n",
    "    ('scaler', StandardScaler())                  # Scale numerical features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Impute missing categorical values with the mode\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # One-hot encode categorical features, handle unknown categories gracefully\n",
    "])\n",
    "\n",
    "# Create a column transformer to apply different transformations to different columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep any other columns (not specified in num or cat) as they are\n",
    ")\n",
    "\n",
    "# --- 5. Model Training (RandomForestClassifier) ---\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the full pipeline: Preprocessing + Classifier\n",
    "full_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('classifier', model)])\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV (for hyperparameter tuning)\n",
    "# This grid has a reduced search space for quicker execution in an example\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200], # Number of trees in the forest\n",
    "    'classifier__max_features': ['sqrt'],   # Number of features to consider when looking for the best split\n",
    "    'classifier__max_depth': [6, 8],        # Maximum depth of the tree\n",
    "    'classifier__criterion': ['gini']       # Function to measure the quality of a split\n",
    "}\n",
    "\n",
    "print(\"\\nStarting GridSearchCV for hyperparameter tuning...\")\n",
    "grid_search = GridSearchCV(estimator=full_pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3, # Using 3-fold cross-validation for reasonable speed\n",
    "                           n_jobs=-1, # Use all available CPU cores for parallel processing\n",
    "                           verbose=2,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# --- 6. Evaluation ---\n",
    "# Evaluate the model on the validation set\n",
    "print(\"\\nEvaluating model on the validation set...\")\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_val):.4f}\")\n",
    "print(\"Classification Report on Validation Set:\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# --- 7. Make Predictions on the Test Set ---\n",
    "print(\"\\nMaking predictions on the test set...\")\n",
    "test_predictions = best_model.predict(test_df)\n",
    "\n",
    "# --- 8. Create Submission File (if needed) ---\n",
    "submission_df = pd.DataFrame({'employee_id': test_employee_ids, 'is_promoted': test_predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nProcess completed. 'submission.csv' has been created with test predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f495972-0f3c-491e-ad2a-3e64522a32a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
